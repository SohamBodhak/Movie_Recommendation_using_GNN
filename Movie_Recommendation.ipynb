{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD1EO8uPlkkP",
        "outputId": "749b3cd0-bc6d-4b2b-e4ff-4dfe5a0d7e65"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.19.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Traditional Way***"
      ],
      "metadata": {
        "id": "lCXg6e7Hk8lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "\n",
        "# Load ratings data (user-item-rating)\n",
        "ratings = pd.read_csv('u.data', sep='\\t', header=None, names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
        "\n",
        "# Load movie information (movie_id and movie_title)\n",
        "movie_info = pd.read_csv('u.item', sep='|', header=None, encoding='latin-1', usecols=[0, 1], names=['item_id', 'movie_title'])\n",
        "\n",
        "# Step 2: Create the User-Item Rating Matrix\n",
        "rating_matrix = ratings.pivot_table(index='user_id', columns='item_id', values='rating')\n",
        "\n",
        "# Step 3: Calculate the Item-Item Similarity Matrix using Cosine Similarity\n",
        "# Fill NaNs with zeros (or you can use a different strategy)\n",
        "rating_matrix = rating_matrix.fillna(0)\n",
        "\n",
        "# Compute cosine similarity between items\n",
        "item_similarity = cosine_similarity(rating_matrix.T)  # Transpose to get items on rows and columns\n",
        "\n",
        "# Step 4: Create a DataFrame for Item Similarity\n",
        "item_similarity_df = pd.DataFrame(item_similarity, index=rating_matrix.columns, columns=rating_matrix.columns)\n",
        "\n",
        "# Step 5: Recommend Items Based on User's Previous Ratings\n",
        "def get_similar_items(user_id, top_k=5):\n",
        "    # Get the items rated by the user\n",
        "    user_ratings = rating_matrix.loc[user_id]\n",
        "    rated_items = user_ratings[user_ratings > 0].index.tolist()\n",
        "\n",
        "    # Create an empty list to store similarity scores\n",
        "    similar_items = {}\n",
        "\n",
        "    # For each item rated by the user, find the most similar items\n",
        "    for item in rated_items:\n",
        "        similar_scores = item_similarity_df[item]\n",
        "\n",
        "        # Add the similarity scores to the dictionary, excluding already rated items\n",
        "        for i, score in similar_scores.items():\n",
        "            if i not in rated_items:\n",
        "                if i in similar_items:\n",
        "                    similar_items[i] += score\n",
        "                else:\n",
        "                    similar_items[i] = score\n",
        "\n",
        "    # Sort the items based on similarity scores (highest first)\n",
        "    recommended_items = sorted(similar_items.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
        "\n",
        "    # Get the movie titles\n",
        "    recommended_movie_ids = [item[0] for item in recommended_items]\n",
        "    recommended_movie_titles = movie_info[movie_info['item_id'].isin(recommended_movie_ids)]['movie_title'].values\n",
        "\n",
        "    return recommended_movie_titles\n",
        "\n",
        "# Example: Recommend 5 items for user 1\n",
        "recommended_movies = get_similar_items(user_id=196, top_k=5)\n",
        "print(\"Recommended Movies for User 1:\")\n",
        "for idx, movie in enumerate(recommended_movies, 1):\n",
        "    print(f\"{idx}. {movie}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDza0bNik10p",
        "outputId": "978011e3-084b-4fc2-c5e1-c0e3833f0f97"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended Movies for User 1:\n",
            "1. Star Wars (1977)\n",
            "2. Monty Python and the Holy Grail (1974)\n",
            "3. Raiders of the Lost Ark (1981)\n",
            "4. Back to the Future (1985)\n",
            "5. When Harry Met Sally... (1989)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Data Preprocessing***"
      ],
      "metadata": {
        "id": "6dI_V61NjfV5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uLfClwzOjGH5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv, GATConv\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load interaction data\n",
        "df = pd.read_csv(\"u.data\", sep='\\t', header=None, names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
        "df.drop(\"timestamp\", axis=1, inplace=True)\n",
        "\n",
        "# Load movie names\n",
        "movie_info = pd.read_csv(\"u.item\", sep='|', encoding='latin-1', header=None, usecols=[0, 1], names=[\"item_id\", \"title\"])\n",
        "\n",
        "# Label encode users/items\n",
        "user_encoder = LabelEncoder()\n",
        "item_encoder = LabelEncoder()\n",
        "df['user'] = user_encoder.fit_transform(df['user_id'])\n",
        "df['item'] = item_encoder.fit_transform(df['item_id'])\n",
        "\n",
        "num_users = df['user'].nunique()\n",
        "num_items = df['item'].nunique()\n",
        "num_nodes = num_users + num_items\n",
        "\n",
        "# Create edge index for user-item graph\n",
        "edges = torch.tensor(df[['user', 'item']].values).T\n",
        "edges[1] += num_users  # shift item IDs to avoid overlap with users\n",
        "\n",
        "edge_index = torch.cat([edges, edges[[1, 0]]], dim=1)  # bidirectional\n",
        "\n",
        "# PyG data\n",
        "data = Data(edge_index=edge_index, num_nodes=num_nodes)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQCk3WPFjK2i",
        "outputId": "f09ecb0b-467d-491d-d861-8fe5a0d2be05"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(edge_index=[2, 200000], num_nodes=2625)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***GCN***"
      ],
      "metadata": {
        "id": "NkuJS3wyjpWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "U7wimfLyjpVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNRecSys(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_dim=64):\n",
        "        super().__init__()\n",
        "        self.embedding_user = nn.Embedding(num_users, embedding_dim)\n",
        "        self.embedding_item = nn.Embedding(num_items, embedding_dim)\n",
        "        self.conv1 = GCNConv(embedding_dim, embedding_dim)\n",
        "        self.conv2 = GCNConv(embedding_dim, embedding_dim)\n",
        "\n",
        "    def forward(self, edge_index):\n",
        "        x = torch.cat([self.embedding_user.weight, self.embedding_item.weight], dim=0)\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "CKrmHI_YjOI4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***GAT***"
      ],
      "metadata": {
        "id": "lFA6FRKSjtlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GATRecSys(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_dim=64, heads=2):\n",
        "        super().__init__()\n",
        "        self.embedding_user = nn.Embedding(num_users, embedding_dim)\n",
        "        self.embedding_item = nn.Embedding(num_items, embedding_dim)\n",
        "        self.gat1 = GATConv(embedding_dim, embedding_dim, heads=heads, concat=True)\n",
        "        self.gat2 = GATConv(embedding_dim * heads, embedding_dim, heads=1, concat=False)\n",
        "\n",
        "    def forward(self, edge_index):\n",
        "        x = torch.cat([self.embedding_user.weight, self.embedding_item.weight], dim=0)\n",
        "        x = F.elu(self.gat1(x, edge_index))\n",
        "        x = self.gat2(x, edge_index)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "8QgjsHqAjRwy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Loss Function***"
      ],
      "metadata": {
        "id": "jw2fC1knjyof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bpr_loss(user_emb, pos_emb, neg_emb):\n",
        "    pos_scores = torch.sum(user_emb * pos_emb, dim=1)\n",
        "    neg_scores = torch.sum(user_emb * neg_emb, dim=1)\n",
        "    return -torch.mean(F.logsigmoid(pos_scores - neg_scores))\n"
      ],
      "metadata": {
        "id": "gAV9AOvajUNJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Training***"
      ],
      "metadata": {
        "id": "yQ4zB7S1j3HY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, data, df, epochs=20, lr=0.01):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        embeddings = model(data.edge_index)\n",
        "\n",
        "        users = torch.tensor(df['user'].values)\n",
        "        pos_items = torch.tensor(df['item'].values)\n",
        "\n",
        "        # Random negative sampling\n",
        "        neg_items = torch.randint(0, num_items, (len(users),))\n",
        "\n",
        "        user_emb = embeddings[users]\n",
        "        pos_emb = embeddings[pos_items + num_users]\n",
        "        neg_emb = embeddings[neg_items + num_users]\n",
        "\n",
        "        loss = bpr_loss(user_emb, pos_emb, neg_emb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "id": "dBGv0SnnjVQY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend(user_id, model, k=5):\n",
        "    model.eval()\n",
        "\n",
        "    # Check if user exists in the dataset\n",
        "    if user_id not in user_encoder.classes_:\n",
        "        print(f\"User {user_id} not found in the dataset.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Get movies the user has already watched from df\n",
        "    watched_movies = df[df['user_id'] == user_id]['item_id'].values\n",
        "    watched_movie_indices = item_encoder.transform(watched_movies) if len(watched_movies) > 0 else np.array([])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Get user and item embeddings\n",
        "        user_idx = user_encoder.transform([user_id])[0]\n",
        "        embeddings = model(data.edge_index)\n",
        "        user_emb = embeddings[user_idx]\n",
        "        item_embs = embeddings[num_users:]\n",
        "\n",
        "        # Compute scores for all items\n",
        "        scores = torch.matmul(item_embs, user_emb)\n",
        "\n",
        "        # Set scores of watched movies to negative infinity to exclude them\n",
        "        if len(watched_movie_indices) > 0:\n",
        "            scores[watched_movie_indices] = float('-inf')\n",
        "\n",
        "        # Get top-k unwatched items\n",
        "        top_items = torch.topk(scores, k=k).indices.numpy()\n",
        "\n",
        "        # Convert encoded item indices to raw item IDs\n",
        "        item_ids = item_encoder.inverse_transform(top_items)\n",
        "\n",
        "        # Return movie information for recommended items\n",
        "        return movie_info[movie_info['item_id'].isin(item_ids)]"
      ],
      "metadata": {
        "id": "NjxJXMXbHEVm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FOnB6IK8HEUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnn_model = GNNRecSys(num_users, num_items)\n",
        "train_model(gnn_model, data, df)\n",
        "\n",
        "print(\"GNN Recommendations for user 196\")\n",
        "print(recommend(196, gnn_model))\n",
        "\n",
        "gat_model = GATRecSys(num_users, num_items)\n",
        "train_model(gat_model, data, df)\n",
        "\n",
        "print(\"GAT Recommendations for user 196\")\n",
        "print(recommend(196, gat_model))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9OyOGjOjZ0I",
        "outputId": "15f17e84-b1c7-4564-fd02-976b84c454cc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 Loss: 0.6788\n",
            "Epoch 2/20 Loss: 0.6031\n",
            "Epoch 3/20 Loss: 0.5397\n",
            "Epoch 4/20 Loss: 0.5374\n",
            "Epoch 5/20 Loss: 0.4814\n",
            "Epoch 6/20 Loss: 0.4753\n",
            "Epoch 7/20 Loss: 0.4676\n",
            "Epoch 8/20 Loss: 0.4440\n",
            "Epoch 9/20 Loss: 0.4354\n",
            "Epoch 10/20 Loss: 0.4316\n",
            "Epoch 11/20 Loss: 0.4255\n",
            "Epoch 12/20 Loss: 0.4229\n",
            "Epoch 13/20 Loss: 0.4281\n",
            "Epoch 14/20 Loss: 0.4187\n",
            "Epoch 15/20 Loss: 0.4111\n",
            "Epoch 16/20 Loss: 0.4101\n",
            "Epoch 17/20 Loss: 0.4013\n",
            "Epoch 18/20 Loss: 0.3927\n",
            "Epoch 19/20 Loss: 0.3879\n",
            "Epoch 20/20 Loss: 0.3763\n",
            "GNN Recommendations for user 196\n",
            "     item_id                      title\n",
            "49        50           Star Wars (1977)\n",
            "99       100               Fargo (1996)\n",
            "180      181  Return of the Jedi (1983)\n",
            "257      258             Contact (1997)\n",
            "293      294           Liar Liar (1997)\n",
            "Epoch 1/20 Loss: 0.6768\n",
            "Epoch 2/20 Loss: 0.6601\n",
            "Epoch 3/20 Loss: 0.6269\n",
            "Epoch 4/20 Loss: 0.4824\n",
            "Epoch 5/20 Loss: 0.4840\n",
            "Epoch 6/20 Loss: 0.4628\n",
            "Epoch 7/20 Loss: 0.4368\n",
            "Epoch 8/20 Loss: 0.4189\n",
            "Epoch 9/20 Loss: 0.4168\n",
            "Epoch 10/20 Loss: 0.4026\n",
            "Epoch 11/20 Loss: 0.3995\n",
            "Epoch 12/20 Loss: 0.3815\n",
            "Epoch 13/20 Loss: 0.3725\n",
            "Epoch 14/20 Loss: 0.3672\n",
            "Epoch 15/20 Loss: 0.3555\n",
            "Epoch 16/20 Loss: 0.3517\n",
            "Epoch 17/20 Loss: 0.3499\n",
            "Epoch 18/20 Loss: 0.3412\n",
            "Epoch 19/20 Loss: 0.3403\n",
            "Epoch 20/20 Loss: 0.3450\n",
            "GAT Recommendations for user 196\n",
            "     item_id                               title\n",
            "120      121       Independence Day (ID4) (1996)\n",
            "180      181           Return of the Jedi (1983)\n",
            "274      275        Sense and Sensibility (1995)\n",
            "470      471           Courage Under Fire (1996)\n",
            "507      508  People vs. Larry Flynt, The (1996)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***LightGCN***"
      ],
      "metadata": {
        "id": "OnTHNB8Uj-Dg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing as pp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from scipy.sparse import coo_matrix, diags\n",
        "\n",
        "\n",
        "df = pd.read_csv('u.data', sep='\\t', header=None)\n",
        "df.columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
        "df = df.drop(columns=['rating', 'timestamp'])\n",
        "\n",
        "\n",
        "# Subsample for faster training\n",
        "sampled_users = df['user_id'].drop_duplicates().sample(n=500, random_state=42)\n",
        "df = df[df['user_id'].isin(sampled_users)]\n",
        "df = df.sample(n=2000, random_state=42)\n",
        "\n",
        "\n",
        "# TRAIN - TEST SPLIT\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "train_users = train_df['user_id'].unique()\n",
        "train_items = train_df['item_id'].unique()\n",
        "test_df = test_df[(test_df['user_id'].isin(train_users)) & (test_df['item_id'].isin(train_items))]\n",
        "\n",
        "le_user = pp.LabelEncoder()\n",
        "le_item = pp.LabelEncoder()\n",
        "\n",
        "train_df['user_id_idx'] = le_user.fit_transform(train_df['user_id'])\n",
        "train_df['item_id_idx'] = le_item.fit_transform(train_df['item_id'])\n",
        "test_df['user_id_idx'] = le_user.transform(test_df['user_id'])\n",
        "test_df['item_id_idx'] = le_item.transform(test_df['item_id'])\n",
        "\n",
        "num_users = train_df['user_id_idx'].nunique()\n",
        "num_items = train_df['item_id_idx'].nunique()\n"
      ],
      "metadata": {
        "id": "WRBplbo4kC0_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Adjacency Matrix***"
      ],
      "metadata": {
        "id": "OB2l5Oi-kUSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_adj_matrix(num_users, num_items, user_item_pairs):\n",
        "    rows = user_item_pairs['user_id_idx']\n",
        "    cols = user_item_pairs['item_id_idx'] + num_users  # shift item index\n",
        "\n",
        "    data = np.ones(len(rows))\n",
        "    adj = coo_matrix((data, (rows, cols)), shape=(num_users + num_items, num_users + num_items))\n",
        "    adj = adj + adj.T\n",
        "\n",
        "    deg = np.array(adj.sum(axis=1)).flatten()\n",
        "    deg_inv_sqrt = np.power(deg, -0.5)\n",
        "    deg_inv_sqrt[np.isinf(deg_inv_sqrt)] = 0.\n",
        "    D_inv_sqrt = diags(deg_inv_sqrt)\n",
        "\n",
        "    norm_adj = D_inv_sqrt @ adj @ D_inv_sqrt\n",
        "    return norm_adj.tocoo()\n"
      ],
      "metadata": {
        "id": "bICWVCjwkTRv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LightGCN(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_dim=64, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
        "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
        "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
        "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def forward(self, norm_adj):\n",
        "        all_embeddings = torch.cat([self.user_embedding.weight, self.item_embedding.weight], dim=0)\n",
        "        out = all_embeddings\n",
        "        embeddings_list = [out]\n",
        "\n",
        "        for _ in range(self.num_layers):\n",
        "            out = torch.sparse.mm(norm_adj, out)\n",
        "            embeddings_list.append(out)\n",
        "\n",
        "        final_embedding = torch.mean(torch.stack(embeddings_list, dim=0), dim=0)\n",
        "        user_embeds = final_embedding[:self.user_embedding.num_embeddings]\n",
        "        item_embeds = final_embedding[self.user_embedding.num_embeddings:]\n",
        "        return user_embeds, item_embeds\n"
      ],
      "metadata": {
        "id": "VCPgb6BkkaVA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BPRLoss(nn.Module):\n",
        "    def forward(self, user_emb, pos_emb, neg_emb):\n",
        "        pos_score = torch.sum(user_emb * pos_emb, dim=1)\n",
        "        neg_score = torch.sum(user_emb * neg_emb, dim=1)\n",
        "        loss = -torch.mean(torch.log(torch.sigmoid(pos_score - neg_score)))\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "Dw87khOckegh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Training***"
      ],
      "metadata": {
        "id": "B7sLeEf0lHYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "adj = build_adj_matrix(num_users, num_items, train_df)\n",
        "indices = torch.tensor([adj.row, adj.col], dtype=torch.long)\n",
        "values = torch.tensor(adj.data, dtype=torch.float32)\n",
        "shape = adj.shape\n",
        "norm_adj = torch.sparse.FloatTensor(indices, values, torch.Size(shape)).to(device)\n",
        "\n",
        "model = LightGCN(num_users, num_items).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = BPRLoss()\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 1024\n",
        "train_df_values = train_df[['user_id_idx', 'item_id_idx']].values\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    user_emb, item_emb = model(norm_adj)\n",
        "    epoch_loss = 0\n",
        "    np.random.shuffle(train_df_values)\n",
        "\n",
        "    for i in range(0, len(train_df_values), batch_size):\n",
        "        batch = train_df_values[i:i+batch_size]\n",
        "        u = torch.tensor(batch[:, 0], dtype=torch.long).to(device)\n",
        "        i_pos = torch.tensor(batch[:, 1], dtype=torch.long).to(device)\n",
        "        j_neg = torch.randint(0, num_items, (len(batch),), dtype=torch.long).to(device)\n",
        "\n",
        "        u_emb = user_emb[u]\n",
        "        i_emb = item_emb[i_pos]\n",
        "        j_emb = item_emb[j_neg]\n",
        "\n",
        "        loss = criterion(u_emb, i_emb, j_emb)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward(retain_graph=True)  # Retain graph if you plan to call backward multiple times\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtzeNOKCkfnA",
        "outputId": "db03541f-c74d-436a-ffd5-4a96078ba4f5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-0f17f89a79c4>:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  indices = torch.tensor([adj.row, adj.col], dtype=torch.long)\n",
            "<ipython-input-15-0f17f89a79c4>:7: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:644.)\n",
            "  norm_adj = torch.sparse.FloatTensor(indices, values, torch.Size(shape)).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.3647\n",
            "Epoch 2, Loss: 1.3361\n",
            "Epoch 3, Loss: 1.2952\n",
            "Epoch 4, Loss: 1.2419\n",
            "Epoch 5, Loss: 1.1791\n",
            "Epoch 6, Loss: 1.1037\n",
            "Epoch 7, Loss: 1.0163\n",
            "Epoch 8, Loss: 0.9157\n",
            "Epoch 9, Loss: 0.8234\n",
            "Epoch 10, Loss: 0.7133\n",
            "Epoch 11, Loss: 0.6182\n",
            "Epoch 12, Loss: 0.5283\n",
            "Epoch 13, Loss: 0.4440\n",
            "Epoch 14, Loss: 0.3727\n",
            "Epoch 15, Loss: 0.3025\n",
            "Epoch 16, Loss: 0.2465\n",
            "Epoch 17, Loss: 0.2044\n",
            "Epoch 18, Loss: 0.1667\n",
            "Epoch 19, Loss: 0.1398\n",
            "Epoch 20, Loss: 0.1139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the movie names from u.item (or any CSV with movie info)\n",
        "movie_info_df = pd.read_csv('u.item', sep='|', header=None, encoding='latin-1')\n",
        "movie_info_df.columns = ['movie_id', 'movie_title', 'release_date', 'video_release_date', 'IMDb_url', 'unknown', 'action', 'adventure', 'animation', 'children', 'comedy', 'crime', 'documentary', 'drama', 'fantasy', 'film_noir', 'horror', 'musical', 'mystery', 'romance', 'sci_fi', 'thriller', 'war', 'western']\n",
        "\n",
        "# Keep only necessary columns\n",
        "movie_info_df = movie_info_df[['movie_id', 'movie_title']]\n"
      ],
      "metadata": {
        "id": "Da8CU27Mkkog"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_movies(user_raw_id, top_k=5):\n",
        "    model.eval()\n",
        "\n",
        "    # Check if user exists in the dataset\n",
        "    if user_raw_id not in le_user.classes_:\n",
        "        print(f\"User {user_raw_id} not found in the dataset.\")\n",
        "        return []\n",
        "\n",
        "    # Transform raw user ID to encoded index\n",
        "    uid = le_user.transform([user_raw_id])[0]\n",
        "\n",
        "    # Get movies the user has already watched (from train_df and optionally test_df)\n",
        "    watched_movies = train_df[train_df['user_id'] == user_raw_id]['item_id'].values\n",
        "    if test_df is not None:\n",
        "        watched_movies = np.union1d(watched_movies, test_df[test_df['user_id'] == user_raw_id]['item_id'].values)\n",
        "\n",
        "    # Get encoded indices of watched movies\n",
        "    watched_movie_indices = le_item.transform(watched_movies) if len(watched_movies) > 0 else np.array([])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Get user and item embeddings\n",
        "        user_emb, item_emb = model(norm_adj)\n",
        "\n",
        "        # Compute scores for all items\n",
        "        scores = torch.matmul(item_emb, user_emb[uid])\n",
        "\n",
        "        # Set scores of watched movies to a very low value (e.g., -infinity) to exclude them\n",
        "        if len(watched_movie_indices) > 0:\n",
        "            scores[watched_movie_indices] = float('-inf')\n",
        "\n",
        "        # Get top-k items (unwatched movies)\n",
        "        top_items = torch.topk(scores, top_k).indices.cpu().numpy()\n",
        "\n",
        "        # Convert encoded item indices to raw movie IDs\n",
        "        movie_ids = le_item.inverse_transform(top_items)\n",
        "\n",
        "        # Get movie titles from movie_info_df\n",
        "        movie_names = movie_info_df[movie_info_df['movie_id'].isin(movie_ids)]['movie_title'].values\n",
        "\n",
        "        return movie_names\n",
        "\n",
        "# Example usage\n",
        "recommended_movies = recommend_movies(user_raw_id=196)\n",
        "print(\"Recommended Movies for User 196 (excluding watched movies):\")\n",
        "for idx, movie in enumerate(recommended_movies, 1):\n",
        "    print(f\"{idx}. {movie}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o8kgOJvknBA",
        "outputId": "b9744793-a9d1-443b-f4d9-79af366fdd57"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended Movies for User 196 (excluding watched movies):\n",
            "1. Angels and Insects (1995)\n",
            "2. Muppet Treasure Island (1996)\n",
            "3. Sense and Sensibility (1995)\n",
            "4. Things to Do in Denver when You're Dead (1995)\n",
            "5. Forbidden Christ, The (Cristo proibito, Il) (1950)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "watched_movies = train_df[train_df['user_id'] == 196]['item_id'].values\n",
        "watched_movie_titles = movie_info_df[movie_info_df['movie_id'].isin(watched_movies)]['movie_title'].values\n",
        "print(\"Watched Movies by User 196:\", watched_movie_titles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbzKAdx3GifF",
        "outputId": "deefe555-c205-4c62-9500-d3aa9bac5f22"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Watched Movies by User 196: ['Boogie Nights (1997)' 'That Thing You Do! (1996)']\n"
          ]
        }
      ]
    }
  ]
}
